{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "import csv\n",
        "\n",
        "# API endpoint\n",
        "apikey = \"de9925c4f3a4401dac15cc99cc1f26cf\"\n",
        "category = \"general\"\n",
        "url = f\"https://gnews.io/api/v4/top-headlines?category={category}&lang=en&country=us&apikey={apikey}\"\n",
        "\n",
        "# Fetch data from API\n",
        "response = requests.get(url)\n",
        "if response.status_code == 200:\n",
        "    data = response.json()  # Assuming the API returns JSON\n",
        "\n",
        "    if \"articles\" in data:\n",
        "      data = data[\"articles\"]\n",
        "    # Define CSV file name\n",
        "    csv_file = \"output.csv\"\n",
        "\n",
        "    # Define required fields based on provided JSON structure\n",
        "    headers = [ \"title\", \"description\", \"url\",  \"image\"]\n",
        "\n",
        "    # Write data to CSV\n",
        "    with open(csv_file, mode='w', newline='', encoding='utf-8') as file:\n",
        "        writer = csv.DictWriter(file, fieldnames=headers)\n",
        "        writer.writeheader()\n",
        "\n",
        "        # Ensure data is a list for consistent writing\n",
        "        if isinstance(data, list):\n",
        "            for item in data:\n",
        "                # Remove unexpected fields\n",
        "                filtered_item = {key: item.get(key, \"\") for key in headers}\n",
        "                # Flatten category list into a comma-separated string)\n",
        "                writer.writerow(filtered_item)\n",
        "        elif isinstance(data, dict):\n",
        "            filtered_data = {key: data.get(key, \"\") for key in headers}\n",
        "            filtered_data[\"category\"] = \", \".join(data.get(\"category\", []))\n",
        "            writer.writerow(filtered_data)\n",
        "\n",
        "    print(f\"Data successfully saved to {csv_file}\")\n",
        "else:\n",
        "    print(\"Failed to fetch data\", response.status_code)"
      ],
      "metadata": {
        "id": "E5kQMqoJbSeg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "48a1ade5-7d96-4dda-c6af-907803174f92"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data successfully saved to output.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "import csv\n",
        "import time\n",
        "import os\n",
        "\n",
        "# API endpoint\n",
        "apikey = \"de9925c4f3a4401dac15cc99cc1f26cf\"\n",
        "category = \"general\"\n",
        "url = f\"https://gnews.io/api/v4/top-headlines?category={category}&lang=en&country=us&max=10&apikey={apikey}\"\n",
        "\n",
        "# CSV file name\n",
        "csv_file = \"output1.csv\"\n",
        "\n",
        "# Define required fields based on provided JSON structure\n",
        "headers = [\"title\", \"description\", \"url\", \"image\"]\n",
        "\n",
        "# Function to fetch and save news data\n",
        "def fetch_and_save_news():\n",
        "    response = requests.get(url)\n",
        "    if response.status_code == 200:\n",
        "        data = response.json()\n",
        "\n",
        "        if \"articles\" in data:\n",
        "            data = data[\"articles\"]\n",
        "\n",
        "        # Check if the file already exists to avoid rewriting headers\n",
        "        file_exists = os.path.isfile(csv_file)\n",
        "\n",
        "        with open(csv_file, mode='a', newline='', encoding='utf-8') as file:\n",
        "            writer = csv.DictWriter(file, fieldnames=headers)\n",
        "\n",
        "            # Write header only if file is newly created\n",
        "            if not file_exists:\n",
        "                writer.writeheader()\n",
        "\n",
        "            # Ensure data is a list for consistent writing\n",
        "            if isinstance(data, list):\n",
        "                for item in data:\n",
        "                    filtered_item = {key: item.get(key, \"\") for key in headers}\n",
        "                    writer.writerow(filtered_item)\n",
        "            elif isinstance(data, dict):\n",
        "                filtered_data = {key: data.get(key, \"\") for key in headers}\n",
        "                writer.writerow(filtered_data)\n",
        "\n",
        "        print(f\"✅ Data successfully saved to {csv_file} at {time.strftime('%Y-%m-%d %H:%M:%S')}\")\n",
        "    else:\n",
        "        print(f\"❌ Failed to fetch data, Status Code: {response.status_code}\")\n",
        "\n",
        "# Run the function every 1 hour\n",
        "while True:\n",
        "    fetch_and_save_news()\n",
        "    print(\"⏳ Waiting for 1 hour before next fetch...\")\n",
        "    time.sleep(3600)  # Wait for 1 hour\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JrgK7QacdD0_",
        "outputId": "97322eb1-7725-44e0-96a5-d79ccd38a088"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Data successfully saved to output1.csv at 2025-03-17 21:45:32\n",
            "⏳ Waiting for 1 hour before next fetch...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "4cZGDxsXi8qw"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}