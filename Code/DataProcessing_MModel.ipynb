{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Loading the data and pre process"
      ],
      "metadata": {
        "id": "JMtoNulv8Isv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import re\n",
        "import pandas as pd\n",
        "import torch\n",
        "import numpy as np\n",
        "import torch.nn as nn\n",
        "import torchvision.models as models\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from PIL import Image\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "from imblearn.over_sampling import RandomOverSampler\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
        "from transformers import BertTokenizer, BertModel\n",
        "from torchvision.models import resnet50, ResNet50_Weights\n",
        "\n",
        "# Load dataset\n",
        "file_path = '/content/drive/MyDrive/All_Data/Cleaned_news_final1.csv'\n",
        "df = pd.read_csv(file_path)\n",
        "\n",
        "# Manual stopwords list\n",
        "manual_stopwords = set([\n",
        "    \"a\", \"an\", \"and\", \"are\", \"as\", \"at\", \"be\", \"but\", \"by\", \"for\", \"if\", \"in\", \"into\", \"is\",\n",
        "    \"it\", \"no\", \"not\", \"of\", \"on\", \"or\", \"such\", \"that\", \"the\", \"their\", \"then\", \"there\",\n",
        "    \"these\", \"they\", \"this\", \"to\", \"was\", \"will\", \"with\", \"we\", \"you\", \"your\"\n",
        "])\n",
        "\n",
        "# Function to preprocess text\n",
        "def preprocess_text(text):\n",
        "    text = text.lower()\n",
        "    text = re.sub(r'\\W', ' ', text)\n",
        "    text = re.sub(r'\\s+', ' ', text)\n",
        "    text = ' '.join([word for word in text.split() if word not in manual_stopwords])\n",
        "    return text\n",
        "\n",
        "# Apply text preprocessing\n",
        "df['cleaned_title'] = df['title'].apply(preprocess_text)\n",
        "df['cleaned_description'] = df['description'].apply(preprocess_text)\n",
        "\n",
        "# Tokenize text using BERT\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
        "df['tokenized_text'] = df['cleaned_description'].apply(lambda x: tokenizer(x, padding='max_length', truncation=True, max_length=512, return_tensors='pt'))\n",
        "\n",
        "# Define image transformation pipeline\n",
        "image_transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "# Define image directory path\n",
        "IMAGE_DIR = '/content/drive/MyDrive/All_Data'\n",
        "\n",
        "# Function to load and preprocess images\n",
        "def load_and_preprocess_image(image_filename):\n",
        "    if isinstance(image_filename, str):\n",
        "        image_filename = image_filename.replace(\"\\\\\", \"/\")  # Convert Windows-style paths\n",
        "        image_path = os.path.join(IMAGE_DIR, image_filename)\n",
        "\n",
        "        if os.path.exists(image_path):\n",
        "            image = Image.open(image_path).convert(\"RGB\")  # Ensure all images have 3 channels (RGB)\n",
        "            return image_transform(image)\n",
        "\n",
        "    return torch.zeros((3, 224, 224))  # Return a blank image tensor if missing\n",
        "\n",
        "# Apply image preprocessing\n",
        "df['processed_image'] = df['image_location'].apply(load_and_preprocess_image)\n",
        "\n",
        "# Convert labels to numerical format\n",
        "df['label_fake_news'] = df['fake_news_label'].apply(lambda x: 1 if x.lower() == 'fake' else 0)\n",
        "df['label_image_relation'] = df['image_relation'].apply(lambda x: 1 if x.lower() == 'yes' else 0)\n",
        "\n",
        "# Handle class imbalance with oversampling\n",
        "ros = RandomOverSampler(sampling_strategy='auto', random_state=42)\n",
        "train_df_resampled, _ = ros.fit_resample(df, df['label_fake_news'])\n",
        "\n",
        "# Split data into train and test sets\n",
        "train_df, test_df = train_test_split(train_df_resampled, test_size=0.2, random_state=42)\n",
        "\n",
        "# Compute class weights for imbalanced dataset\n",
        "class_weights = compute_class_weight(class_weight='balanced', classes=np.array([0, 1]), y=train_df['label_fake_news'].values)\n",
        "class_weights = torch.tensor(class_weights, dtype=torch.float)\n",
        "\n",
        "# Define Multimodal Model with Dual Output\n",
        "class MultiModalFakeNewsModel(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(MultiModalFakeNewsModel, self).__init__()\n",
        "\n",
        "        # Text Model (BERT)\n",
        "        self.text_model = BertModel.from_pretrained(\"bert-base-uncased\")\n",
        "        self.text_fc = nn.Linear(768, 256)\n",
        "\n",
        "        # Image Model (ResNet-50)\n",
        "        self.image_model = resnet50(weights=ResNet50_Weights.IMAGENET1K_V1)\n",
        "        self.image_model.fc = nn.Linear(self.image_model.fc.in_features, 256)\n",
        "\n",
        "        # Fusion Layer\n",
        "        self.fusion_fc = nn.Linear(512, 256)\n",
        "\n",
        "        # Output Layers\n",
        "        self.fc_fake_news = nn.Linear(256, 1)  # Fake News Classification\n",
        "        self.fc_image_relation = nn.Linear(256, 1)  # Image-Text Relationship Classification\n",
        "\n",
        "        self.sigmoid = nn.Sigmoid()\n",
        "\n",
        "    def forward(self, text_input, attention_mask, image_input):\n",
        "        text_features = self.text_model(text_input, attention_mask=attention_mask).pooler_output\n",
        "        text_features = self.text_fc(text_features)\n",
        "\n",
        "        image_features = self.image_model(image_input)\n",
        "\n",
        "        combined = torch.cat((text_features, image_features), dim=1)\n",
        "        fused_features = self.fusion_fc(combined)\n",
        "\n",
        "        output_fake_news = self.fc_fake_news(fused_features)\n",
        "        output_image_relation = self.fc_image_relation(fused_features)\n",
        "\n",
        "        return self.sigmoid(output_fake_news), self.sigmoid(output_image_relation)\n",
        "# Define Model Training Function\n",
        "def train_model(model, train_loader, criterion_fake_news, criterion_image_relation, optimizer, device, num_epochs=10):\n",
        "    model.to(device)\n",
        "    model.train()\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        total_loss = 0\n",
        "        for text_data, image_data, label_fake_news, label_image_relation in train_loader:\n",
        "            text_input_ids = text_data[\"input_ids\"].squeeze(1).to(device)\n",
        "            attention_mask = text_data[\"attention_mask\"].squeeze(1).to(device)\n",
        "            image_data = image_data.to(device)\n",
        "            label_fake_news = label_fake_news.to(device)\n",
        "            label_image_relation = label_image_relation.to(device)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            output_fake_news, output_image_relation = model(text_input_ids, attention_mask, image_data)\n",
        "\n",
        "            loss_fake_news = criterion_fake_news(output_fake_news.squeeze(), label_fake_news)\n",
        "            loss_image_relation = criterion_image_relation(output_image_relation.squeeze(), label_image_relation)\n",
        "\n",
        "            loss = loss_fake_news + loss_image_relation  # Total loss\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            total_loss += loss.item()\n",
        "\n",
        "        print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {total_loss/len(train_loader):.4f}\")\n",
        "\n",
        "# Define PyTorch Dataset class\n",
        "class NewsDataset(Dataset):\n",
        "    def __init__(self, dataframe):\n",
        "        self.data = dataframe\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        text_data = self.data.iloc[idx]['tokenized_text']\n",
        "        image_data = self.data.iloc[idx]['processed_image']\n",
        "        label_fake_news = torch.tensor(self.data.iloc[idx]['label_fake_news'], dtype=torch.float)\n",
        "        label_image_relation = torch.tensor(self.data.iloc[idx]['label_image_relation'], dtype=torch.float)\n",
        "        return text_data, image_data, label_fake_news, label_image_relation\n",
        "\n",
        "# Create DataLoaders\n",
        "train_dataset = NewsDataset(train_df)\n",
        "test_dataset = NewsDataset(test_df)\n",
        "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=16, shuffle=False)\n",
        "\n",
        "# Initialize Model, Loss, Optimizer\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = MultiModalFakeNewsModel().to(device)\n",
        "criterion_fake_news = nn.BCEWithLogitsLoss(pos_weight=class_weights[1])\n",
        "criterion_image_relation = nn.BCELoss()\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr=5e-5)\n",
        "\n",
        "# Train the Model\n",
        "train_model(model, train_loader, criterion_fake_news, criterion_image_relation, optimizer, device, num_epochs=10)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6CtqL3wSLhCf",
        "outputId": "8d3b1899-d5bf-4f62-cc0b-cbeeb9c64616"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/PIL/Image.py:1045: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10, Loss: 0.9316\n",
            "Epoch 2/10, Loss: 0.6653\n",
            "Epoch 3/10, Loss: 0.5679\n",
            "Epoch 4/10, Loss: 0.5411\n",
            "Epoch 5/10, Loss: 0.5255\n",
            "Epoch 6/10, Loss: 0.5244\n",
            "Epoch 7/10, Loss: 0.5107\n",
            "Epoch 8/10, Loss: 0.5186\n",
            "Epoch 9/10, Loss: 0.5154\n",
            "Epoch 10/10, Loss: 0.5147\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate Model\n",
        "# Define Model Evaluation Function\n",
        "def evaluate_model(model, dataloader, device):\n",
        "    model.eval()\n",
        "    all_preds_fake_news, all_labels_fake_news = [], []\n",
        "    all_preds_image_relation, all_labels_image_relation = [], []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for text_data, image_data, label_fake_news, label_image_relation in dataloader:\n",
        "            text_input_ids = text_data[\"input_ids\"].squeeze(1).to(device)\n",
        "            attention_mask = text_data[\"attention_mask\"].squeeze(1).to(device)\n",
        "            image_data = image_data.to(device)\n",
        "            label_fake_news = label_fake_news.to(device)\n",
        "            label_image_relation = label_image_relation.to(device)\n",
        "\n",
        "            output_fake_news, output_image_relation = model(text_input_ids, attention_mask, image_data)\n",
        "\n",
        "            predicted_fake_news = (output_fake_news.squeeze() > 0.5).float()\n",
        "            predicted_image_relation = (output_image_relation.squeeze() > 0.5).float()\n",
        "\n",
        "            all_preds_fake_news.extend(predicted_fake_news.cpu().numpy())\n",
        "            all_labels_fake_news.extend(label_fake_news.cpu().numpy())\n",
        "\n",
        "            all_preds_image_relation.extend(predicted_image_relation.cpu().numpy())\n",
        "            all_labels_image_relation.extend(label_image_relation.cpu().numpy())\n",
        "\n",
        "    # Calculate Metrics\n",
        "    metrics = {\n",
        "        \"Fake News Accuracy\": accuracy_score(all_labels_fake_news, all_preds_fake_news),\n",
        "        \"Fake News Precision\": precision_score(all_labels_fake_news, all_preds_fake_news, zero_division=1),\n",
        "        \"Fake News Recall\": recall_score(all_labels_fake_news, all_preds_fake_news, zero_division=1),\n",
        "        \"Fake News F1-score\": f1_score(all_labels_fake_news, all_preds_fake_news, zero_division=1),\n",
        "        \"Fake News AUC-ROC\": roc_auc_score(all_labels_fake_news, all_preds_fake_news),\n",
        "        \"Image Relation Accuracy\": accuracy_score(all_labels_image_relation, all_preds_image_relation),\n",
        "        \"Image Relation Precision\": precision_score(all_labels_image_relation, all_preds_image_relation, zero_division=1),\n",
        "        \"Image Relation Recall\": recall_score(all_labels_image_relation, all_preds_image_relation, zero_division=1),\n",
        "        \"Image Relation F1-score\": f1_score(all_labels_image_relation, all_preds_image_relation, zero_division=1),\n",
        "        \"Image Relation AUC-ROC\": roc_auc_score(all_labels_image_relation, all_preds_image_relation)\n",
        "    }\n",
        "\n",
        "    return metrics\n",
        "\n",
        "evaluation_results = evaluate_model(model, test_loader, device)\n",
        "for metric, value in evaluation_results.items():\n",
        "    print(f\"{metric}: {value:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SgzmpzmfQFMu",
        "outputId": "65b75a0c-b641-4a02-9ad3-69887f426421"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fake News Accuracy: 1.0000\n",
            "Fake News Precision: 1.0000\n",
            "Fake News Recall: 1.0000\n",
            "Fake News F1-score: 1.0000\n",
            "Fake News AUC-ROC: 1.0000\n",
            "Image Relation Accuracy: 0.9273\n",
            "Image Relation Precision: 0.9286\n",
            "Image Relation Recall: 0.9750\n",
            "Image Relation F1-score: 0.9512\n",
            "Image Relation AUC-ROC: 0.8875\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "yw99HU9WwSpe"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}