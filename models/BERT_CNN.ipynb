{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rajar\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "C:\\Users\\rajar\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5, Loss: 0.5094402459534731\n",
      "Epoch 2/5, Loss: 0.3402996063232422\n",
      "Epoch 3/5, Loss: 0.2313016178933057\n",
      "Epoch 4/5, Loss: 0.1529625044627623\n",
      "Epoch 5/5, Loss: 0.10971758785572919\n",
      "Test Accuracy: 1.0\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from transformers import BertTokenizer, BertModel\n",
    "from torchvision import models, transforms\n",
    "from PIL import Image\n",
    "import pandas as pd\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
    "import numpy as np\n",
    "\n",
    "# Load and Split Dataset\n",
    "df = pd.read_csv('politifact_cleaned_filtered.csv')\n",
    "# Drop rows with missing values\n",
    "df = df.dropna(subset=['Claim', 'Image Filename', 'Rating'])\n",
    "\n",
    "train_df, temp_df = train_test_split(df, test_size=0.3, random_state=42, stratify=df['Rating'])\n",
    "val_df, test_df = train_test_split(temp_df, test_size=0.5, random_state=42, stratify=temp_df['Rating'])\n",
    "\n",
    "train_df.to_csv('train_data.csv', index=False)\n",
    "val_df.to_csv('val_data.csv', index=False)\n",
    "test_df.to_csv('test_data.csv', index=False)\n",
    "\n",
    "# Load BERT Tokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "\n",
    "# Define Text + Image Dataset\n",
    "class FakeNewsDataset(Dataset):\n",
    "    def __init__(self, csv_file, image_dir, tokenizer, max_length=128):\n",
    "        self.data = pd.read_csv(csv_file)\n",
    "        self.image_dir = image_dir\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "        self.transform = transforms.Compose([\n",
    "            transforms.Resize((224, 224)),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "        ])\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        text = self.data.iloc[idx]['Claim']\n",
    "        image_filename = self.data.iloc[idx]['Image Filename']\n",
    "        label = 1 if self.data.iloc[idx]['Rating'] == 'True' else 0\n",
    "        \n",
    "        encoding = self.tokenizer(text, padding='max_length', truncation=True, max_length=self.max_length, return_tensors='pt')\n",
    "        input_ids = encoding['input_ids'].squeeze(0)\n",
    "        attention_mask = encoding['attention_mask'].squeeze(0)\n",
    "        \n",
    "        image_path = f\"{self.image_dir}/{image_filename}\"\n",
    "        try:\n",
    "            image = Image.open(image_path).convert('RGB')\n",
    "            image = self.transform(image)\n",
    "        except:\n",
    "            image = torch.zeros(3, 224, 224)  # Handle missing images\n",
    "        \n",
    "        return input_ids, attention_mask, image, torch.tensor(label, dtype=torch.long)\n",
    "\n",
    "# Define the Multimodal Model\n",
    "class MultimodalFakeNewsModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MultimodalFakeNewsModel, self).__init__()\n",
    "        \n",
    "        # BERT for text processing\n",
    "        self.bert = BertModel.from_pretrained('bert-base-uncased')\n",
    "        self.text_fc = nn.Linear(768, 256)\n",
    "        \n",
    "        # ResNet for image processing\n",
    "        self.resnet = models.resnet50(pretrained=True)\n",
    "        self.resnet.fc = nn.Identity()  # Remove final classification layer\n",
    "        self.image_fc = nn.Linear(2048, 256)\n",
    "        \n",
    "        # Fusion and classification\n",
    "        self.fc1 = nn.Linear(512, 128)\n",
    "        self.fc2 = nn.Linear(128, 1)\n",
    "        self.dropout = nn.Dropout(0.3)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "    \n",
    "    def forward(self, input_ids, attention_mask, images):\n",
    "        # Text embedding\n",
    "        text_out = self.bert(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        text_feat = self.text_fc(text_out.pooler_output)\n",
    "        text_feat = self.relu(text_feat)\n",
    "        \n",
    "        # Image embedding\n",
    "        image_feat = self.resnet(images)\n",
    "        image_feat = self.image_fc(image_feat)\n",
    "        image_feat = self.relu(image_feat)\n",
    "        \n",
    "        # Concatenate text and image features\n",
    "        combined = torch.cat((text_feat, image_feat), dim=1)\n",
    "        combined = self.relu(self.fc1(combined))\n",
    "        combined = self.dropout(combined)\n",
    "        output = self.sigmoid(self.fc2(combined))\n",
    "        \n",
    "        return output.squeeze(1)\n",
    "\n",
    "# Training Setup\n",
    "def train(model, train_dataloader, val_dataloader, criterion, optimizer, device, epochs=5):\n",
    "    model.to(device)\n",
    "    model.train()\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        total_loss = 0\n",
    "        for input_ids, attention_mask, images, labels in train_dataloader:\n",
    "            input_ids, attention_mask, images, labels = input_ids.to(device), attention_mask.to(device), images.to(device), labels.to(device, dtype=torch.float)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(input_ids, attention_mask, images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            total_loss += loss.item()\n",
    "        \n",
    "        print(f\"Epoch {epoch+1}/{epochs}, Loss: {total_loss/len(train_dataloader)}\")\n",
    "        \n",
    "        # Evaluate on validation set\n",
    "def evaluate(model, dataloader, device):\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "    \n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for input_ids, attention_mask, images, labels in dataloader:\n",
    "            input_ids, attention_mask, images, labels = (\n",
    "                input_ids.to(device), \n",
    "                attention_mask.to(device), \n",
    "                images.to(device), \n",
    "                labels.to(device, dtype=torch.float)\n",
    "            )\n",
    "\n",
    "            outputs = model(input_ids, attention_mask, images)\n",
    "            preds = (outputs > 0.5).cpu().numpy()\n",
    "            all_preds.extend(preds)\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "    return accuracy_score(all_labels, all_preds)\n",
    "\n",
    "# Load Data and Train\n",
    "if __name__ == \"__main__\":\n",
    "    train_dataset = FakeNewsDataset('train_data.csv', 'path/to/images', tokenizer)\n",
    "    train_dataloader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
    "    \n",
    "    val_dataset = FakeNewsDataset('val_data.csv', 'path/to/images', tokenizer)\n",
    "    val_dataloader = DataLoader(val_dataset, batch_size=16, shuffle=False)\n",
    "    \n",
    "    test_dataset = FakeNewsDataset('test_data.csv', 'path/to/images', tokenizer)\n",
    "    test_dataloader = DataLoader(test_dataset, batch_size=16, shuffle=False)\n",
    "    \n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model = MultimodalFakeNewsModel()\n",
    "    \n",
    "    criterion = nn.BCELoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=2e-5)\n",
    "    \n",
    "    train(model, train_dataloader, val_dataloader, criterion, optimizer, device, epochs=5)\n",
    "    \n",
    "    test_accuracy = evaluate(model, test_dataloader, device)\n",
    "    print(f\"Test Accuracy: {test_accuracy}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved successfully.\n"
     ]
    }
   ],
   "source": [
    "# Save the trained model after training\n",
    "torch.save(model.state_dict(), \"multimodal_fake_news.pth\")\n",
    "print(\"Model saved successfully.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Accuracy': 1.0, 'Precision': 0.0, 'Recall': 0.0, 'F1 Score': 0.0, 'Confusion Matrix': [[37]], 'Class Accuracy': [1.0]}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rajar\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\rajar\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\rajar\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\rajar\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\sklearn\\metrics\\_classification.py:407: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from transformers import BertTokenizer, BertModel\n",
    "from torchvision import models, transforms\n",
    "from PIL import Image\n",
    "import pandas as pd\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
    "import numpy as np\n",
    "\n",
    "# Load and Split Dataset\n",
    "df = pd.read_csv('politifact_cleaned_filtered.csv')\n",
    "df = df.dropna(subset=['Claim', 'Image Filename', 'Rating'])  # Handle NaN values\n",
    "train_df, temp_df = train_test_split(df, test_size=0.3, random_state=42, stratify=df['Rating'])\n",
    "val_df, test_df = train_test_split(temp_df, test_size=0.5, random_state=42, stratify=temp_df['Rating'])\n",
    "\n",
    "train_df.to_csv('train_data.csv', index=False)\n",
    "val_df.to_csv('val_data.csv', index=False)\n",
    "test_df.to_csv('test_data.csv', index=False)\n",
    "\n",
    "# Load BERT Tokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "\n",
    "# Define Text + Image Dataset\n",
    "class FakeNewsDataset(Dataset):\n",
    "    def __init__(self, csv_file, image_dir, tokenizer, max_length=128):\n",
    "        self.data = pd.read_csv(csv_file)\n",
    "        self.image_dir = image_dir\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "        self.transform = transforms.Compose([\n",
    "            transforms.Resize((224, 224)),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "        ])\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        text = self.data.iloc[idx]['Claim']\n",
    "        image_filename = self.data.iloc[idx]['Image Filename']\n",
    "        label = 1 if self.data.iloc[idx]['Rating'] == 'True' else 0\n",
    "        \n",
    "        encoding = self.tokenizer(text, padding='max_length', truncation=True, max_length=self.max_length, return_tensors='pt')\n",
    "        input_ids = encoding['input_ids'].squeeze(0)\n",
    "        attention_mask = encoding['attention_mask'].squeeze(0)\n",
    "        \n",
    "        image_path = f\"{self.image_dir}/{image_filename}\"\n",
    "        try:\n",
    "            image = Image.open(image_path).convert('RGB')\n",
    "            image = self.transform(image)\n",
    "        except:\n",
    "            image = torch.zeros(3, 224, 224)  # Handle missing images\n",
    "        \n",
    "        return input_ids, attention_mask, image, torch.tensor(label, dtype=torch.long)\n",
    "\n",
    "# Define the Multimodal Model\n",
    "class MultimodalFakeNewsModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MultimodalFakeNewsModel, self).__init__()\n",
    "        \n",
    "        # BERT for text processing\n",
    "        self.bert = BertModel.from_pretrained('bert-base-uncased')\n",
    "        self.text_fc = nn.Linear(768, 256)\n",
    "        \n",
    "        # ResNet for image processing\n",
    "        self.resnet = models.resnet50(weights=models.ResNet50_Weights.IMAGENET1K_V1)\n",
    "        self.resnet.fc = nn.Identity()  # Remove final classification layer\n",
    "        self.image_fc = nn.Linear(2048, 256)\n",
    "        \n",
    "        # Fusion and classification\n",
    "        self.fc1 = nn.Linear(512, 128)\n",
    "        self.fc2 = nn.Linear(128, 1)\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "    \n",
    "    def forward(self, input_ids, attention_mask, images):\n",
    "        # Text embedding\n",
    "        text_out = self.bert(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        text_feat = self.text_fc(text_out.pooler_output)\n",
    "        text_feat = self.relu(text_feat)\n",
    "        \n",
    "        # Image embedding\n",
    "        image_feat = self.resnet(images)\n",
    "        image_feat = self.image_fc(image_feat)\n",
    "        image_feat = self.relu(image_feat)\n",
    "        \n",
    "        # Concatenate text and image features\n",
    "        combined = torch.cat((text_feat, image_feat), dim=1)\n",
    "        combined = self.relu(self.fc1(combined))\n",
    "        combined = self.dropout(combined)\n",
    "        output = self.sigmoid(self.fc2(combined))\n",
    "        \n",
    "        return output.squeeze(1)\n",
    "\n",
    "# Evaluation Function with Class Accuracy\n",
    "def evaluate(model, dataloader, device):\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "    \n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for input_ids, attention_mask, images, labels in dataloader:\n",
    "            input_ids, attention_mask, images, labels = (\n",
    "                input_ids.to(device), \n",
    "                attention_mask.to(device), \n",
    "                images.to(device), \n",
    "                labels.to(device, dtype=torch.float)\n",
    "            )\n",
    "\n",
    "            outputs = model(input_ids, attention_mask, images)\n",
    "            preds = (outputs > 0.5).cpu().numpy()\n",
    "            all_preds.extend(preds)\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "    all_preds = np.array(all_preds)\n",
    "    all_labels = np.array(all_labels)\n",
    "\n",
    "    accuracy = accuracy_score(all_labels, all_preds)\n",
    "    precision = precision_score(all_labels, all_preds)\n",
    "    recall = recall_score(all_labels, all_preds)\n",
    "    f1 = f1_score(all_labels, all_preds)\n",
    "    conf_matrix = confusion_matrix(all_labels, all_preds)\n",
    "    class_accuracy = conf_matrix.diagonal() / conf_matrix.sum(axis=1)\n",
    "\n",
    "    return {\n",
    "        \"Accuracy\": accuracy,\n",
    "        \"Precision\": precision,\n",
    "        \"Recall\": recall,\n",
    "        \"F1 Score\": f1,\n",
    "        \"Confusion Matrix\": conf_matrix.tolist(),\n",
    "        \"Class Accuracy\": class_accuracy.tolist()\n",
    "    }\n",
    "\n",
    "# Load Data and Evaluate\n",
    "if __name__ == \"__main__\":\n",
    "    test_dataset = FakeNewsDataset('test_data.csv', 'path/to/images', tokenizer)\n",
    "    test_dataloader = DataLoader(test_dataset, batch_size=16, shuffle=False)\n",
    "    \n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model = MultimodalFakeNewsModel()\n",
    "    model.load_state_dict(torch.load(\"multimodal_fake_news.pth\"))  # Load trained weights\n",
    "    \n",
    "    evaluation_results = evaluate(model, test_dataloader, device)\n",
    "    print(evaluation_results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
