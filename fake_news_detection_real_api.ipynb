{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fake News Detection with Web Search Integration\n",
    "\n",
    "This notebook provides a complete implementation of a fake news detection system that uses web search capabilities to verify claims. The system can work independently or be integrated with a CLIP-based model for enhanced detection.\n",
    "\n",
    "## Overview\n",
    "\n",
    "The system works by:\n",
    "1. Extracting claims from news text\n",
    "2. Checking these claims against fact-checking sources\n",
    "3. Determining the credibility of the news based on fact-check results\n",
    "4. (Optional) Integrating with a CLIP model for multimodal analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup and Installation\n",
    "\n",
    "First, let's install the required packages:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Install required packages\n",
    "!pip install nltk requests pandas\n",
    "\n",
    "# Optional: Install PyTorch and transformers if you want to use the CLIP model integration\n",
    "# !pip install torch transformers\n",
    "\n",
    "# Download NLTK resources\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "\n",
    "# Import other required libraries\n",
    "import os\n",
    "import re\n",
    "import json\n",
    "import requests\n",
    "import logging\n",
    "from typing import List, Dict, Any, Optional, Tuple\n",
    "\n",
    "# Configure logging\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'\n",
    ")\n",
    "logger = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. API Key Setup\n",
    "\n",
    "Enter your Google Fact Check API key below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Set your API key here\n",
    "API_KEY = input(\"Enter your Google Fact Check API key: \")\n",
    "\n",
    "# Verify API key is provided\n",
    "if not API_KEY:\n",
    "    print(\"Warning: No API key provided. The system will not be able to perform fact-checking.\")\n",
    "else:\n",
    "    print(\"API key set successfully!\")\n",
    "    \n",
    "# Set as environment variable (optional)\n",
    "os.environ[\"FACT_CHECK_API_KEY\"] = API_KEY"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Claim Extractor Implementation\n",
    "\n",
    "This component extracts potential claims from news text for fact-checking."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "class ClaimExtractor:\n",
    "    \"\"\"\n",
    "    Module for extracting claims from news text for fact-checking.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        \"\"\"Initialize the ClaimExtractor.\"\"\"\n",
    "        # Claim indicator phrases\n",
    "        self.claim_indicators = [\n",
    "            \"claims that\", \"stated that\", \"says that\", \"according to\",\n",
    "            \"reported that\", \"announced that\", \"declared that\", \"asserted that\",\n",
    "            \"confirmed that\", \"denied that\", \"suggested that\", \"alleged that\",\n",
    "            \"revealed that\", \"mentioned that\", \"indicated that\", \"argued that\"\n",
    "        ]\n",
    "        \n",
    "        # Patterns for direct quotes\n",
    "        self.quote_pattern = re.compile(r'\"([^\"]*)\"')\n",
    "        \n",
    "    def extract_claims(self, text: str) -> List[str]:\n",
    "        \"\"\"\n",
    "        Extract potential claims from text.\n",
    "        \n",
    "        Args:\n",
    "            text: The news text to analyze\n",
    "            \n",
    "        Returns:\n",
    "            List of extracted claim strings\n",
    "        \"\"\"\n",
    "        if not text:\n",
    "            logger.warning(\"Empty text provided for claim extraction\")\n",
    "            return []\n",
    "        \n",
    "        # Tokenize text into sentences\n",
    "        sentences = nltk.sent_tokenize(text)\n",
    "        \n",
    "        # Extract claims using multiple methods\n",
    "        claims = []\n",
    "        claims.extend(self._extract_indicator_claims(sentences))\n",
    "        claims.extend(self._extract_quote_claims(text))\n",
    "        claims.extend(self._extract_statement_claims(sentences))\n",
    "        \n",
    "        # Remove duplicates and very short claims\n",
    "        unique_claims = []\n",
    "        for claim in claims:\n",
    "            claim = claim.strip()\n",
    "            if claim and len(claim) > 15 and claim not in unique_claims:\n",
    "                unique_claims.append(claim)\n",
    "        \n",
    "        logger.info(f\"Extracted {len(unique_claims)} unique claims from text\")\n",
    "        return unique_claims\n",
    "    \n",
    "    def _extract_indicator_claims(self, sentences: List[str]) -> List[str]:\n",
    "        \"\"\"\n",
    "        Extract claims based on indicator phrases.\n",
    "        \n",
    "        Args:\n",
    "            sentences: List of sentences from the text\n",
    "            \n",
    "        Returns:\n",
    "            List of claims extracted using indicator phrases\n",
    "        \"\"\"\n",
    "        claims = []\n",
    "        \n",
    "        for sentence in sentences:\n",
    "            for indicator in self.claim_indicators:\n",
    "                if indicator in sentence.lower():\n",
    "                    # Split by the indicator and take the part after it\n",
    "                    parts = sentence.lower().split(indicator, 1)\n",
    "                    if len(parts) > 1:\n",
    "                        claim = parts[1].strip()\n",
    "                        # Clean up the claim\n",
    "                        claim = re.sub(r'^\\s*that\\s+', '', claim)\n",
    "                        claims.append(claim)\n",
    "        \n",
    "        return claims\n",
    "    \n",
    "    def _extract_quote_claims(self, text: str) -> List[str]:\n",
    "        \"\"\"\n",
    "        Extract claims from quoted text.\n",
    "        \n",
    "        Args:\n",
    "            text: The full text\n",
    "            \n",
    "        Returns:\n",
    "            List of claims extracted from quotes\n",
    "        \"\"\"\n",
    "        # Find all quoted text\n",
    "        quotes = self.quote_pattern.findall(text)\n",
    "        \n",
    "        # Filter out short quotes or those that don't look like claims\n",
    "        claims = []\n",
    "        for quote in quotes:\n",
    "            if len(quote) > 15 and any(word in quote.lower() for word in [\"is\", \"are\", \"was\", \"were\", \"will\", \"has\", \"have\"]):\n",
    "                claims.append(quote)\n",
    "        \n",
    "        return claims\n",
    "    \n",
    "    def _extract_statement_claims(self, sentences: List[str]) -> List[str]:\n",
    "        \"\"\"\n",
    "        Extract claims that appear to be statements of fact.\n",
    "        \n",
    "        Args:\n",
    "            sentences: List of sentences from the text\n",
    "            \n",
    "        Returns:\n",
    "            List of claims that appear to be statements of fact\n",
    "        \"\"\"\n",
    "        claims = []\n",
    "        \n",
    "        for sentence in sentences:\n",
    "            # Skip very short sentences\n",
    "            if len(sentence) < 20:\n",
    "                continue\n",
    "                \n",
    "            # POS tagging to identify sentence structure\n",
    "            tagged = nltk.pos_tag(nltk.word_tokenize(sentence))\n",
    "            \n",
    "            # Check if the sentence starts with a proper noun or pronoun followed by a verb\n",
    "            if len(tagged) > 2:\n",
    "                first_tag = tagged[0][1]\n",
    "                second_tag = tagged[1][1]\n",
    "                \n",
    "                # Check for patterns like \"NNP VBZ\" (e.g., \"Trump says\") or \"PRP VBZ\" (e.g., \"He claims\")\n",
    "                if (first_tag.startswith('NNP') and second_tag.startswith('VB')) or \\\n",
    "                   (first_tag.startswith('PRP') and second_tag.startswith('VB')):\n",
    "                    claims.append(sentence)\n",
    "                \n",
    "                # Check for sentences with factual verbs\n",
    "                factual_verbs = [\"is\", \"are\", \"was\", \"were\", \"will\", \"has\", \"have\", \"shows\", \"reveals\", \"confirms\", \"proves\"]\n",
    "                if any(word.lower() in factual_verbs for word, tag in tagged):\n",
    "                    claims.append(sentence)\n",
    "        \n",
    "        return claims\n",
    "    \n",
    "    def rank_claims(self, claims: List[str], top_n: int = 3) -> List[str]:\n",
    "        \"\"\"\n",
    "        Rank claims by importance and return the top N.\n",
    "        \n",
    "        Args:\n",
    "            claims: List of extracted claims\n",
    "            top_n: Number of top claims to return\n",
    "            \n",
    "        Returns:\n",
    "            List of top N ranked claims\n",
    "        \"\"\"\n",
    "        if not claims:\n",
    "            return []\n",
    "        \n",
    "        # Simple ranking based on length and presence of key terms\n",
    "        ranked_claims = []\n",
    "        for claim in claims:\n",
    "            score = 0\n",
    "            \n",
    "            # Longer claims might be more substantial\n",
    "            score += min(len(claim) / 20, 3)\n",
    "            \n",
    "            # Claims with numbers might be more verifiable\n",
    "            if re.search(r'\\d+', claim):\n",
    "                score += 2\n",
    "                \n",
    "            # Claims with named entities might be more important\n",
    "            if re.search(r'[A-Z][a-z]+(?:\\s+[A-Z][a-z]+)+', claim):\n",
    "                score += 2\n",
    "                \n",
    "            # Claims with certain keywords might be more important\n",
    "            importance_keywords = [\"percent\", \"study\", \"research\", \"found\", \"according\", \"evidence\", \"data\", \"report\"]\n",
    "            for keyword in importance_keywords:\n",
    "                if keyword in claim.lower():\n",
    "                    score += 1\n",
    "            \n",
    "            ranked_claims.append((claim, score))\n",
    "        \n",
    "        # Sort by score in descending order\n",
    "        ranked_claims.sort(key=lambda x: x[1], reverse=True)\n",
    "        \n",
    "        # Return top N claims\n",
    "        return [claim for claim, score in ranked_claims[:top_n]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Web Search Module Implementation\n",
    "\n",
    "This component handles the interaction with the Google Fact Check API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "class WebSearchModule:\n",
    "    \"\"\"\n",
    "    Module for performing web searches to fact-check claims using the Google Fact Check API.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, api_key: Optional[str] = None):\n",
    "        \"\"\"\n",
    "        Initialize the WebSearchModule.\n",
    "        \n",
    "        Args:\n",
    "            api_key: API key for the Google Fact Check API\n",
    "        \"\"\"\n",
    "        self.api_key = api_key or os.environ.get(\"FACT_CHECK_API_KEY\")\n",
    "        if not self.api_key:\n",
    "            logger.warning(\"No API key provided. Fact-checking functionality will not work.\")\n",
    "            \n",
    "        self.fact_check_base_url = \"https://factchecktools.googleapis.com/v1alpha1/claims:search\"\n",
    "        self.cache = {}  # Simple in-memory cache\n",
    "    \n",
    "    def fact_check_claim(self, claim: str, language_code: str = \"en\") -> Dict[str, Any]:\n",
    "        \"\"\"\n",
    "        Query the Google Fact Check API for a specific claim.\n",
    "        \n",
    "        Args:\n",
    "            claim: The claim text to fact-check\n",
    "            language_code: BCP-47 language code (default: \"en\")\n",
    "            \n",
    "        Returns:\n",
    "            Dictionary containing fact-check results\n",
    "        \"\"\"\n",
    "        # Check if API key is available\n",
    "        if not self.api_key:\n",
    "            logger.error(\"Cannot fact-check claim: No API key provided\")\n",
    "            return {\"error\": \"No API key provided\", \"claims\": []}\n",
    "        \n",
    "        # Check cache first\n",
    "        cache_key = f\"{claim}_{language_code}\"\n",
    "        if cache_key in self.cache:\n",
    "            logger.info(f\"Cache hit for claim: {claim[:30]}...\")\n",
    "            return self.cache[cache_key]\n",
    "        \n",
    "        # Prepare request parameters\n",
    "        params = {\n",
    "            \"key\": self.api_key,\n",
    "            \"query\": claim,\n",
    "            \"languageCode\": language_code\n",
    "        }\n",
    "        \n",
    "        try:\n",
    "            logger.info(f\"Querying Google Fact Check API for claim: {claim[:30]}...\")\n",
    "            response = requests.get(self.fact_check_base_url, params=params)\n",
    "            response.raise_for_status()\n",
    "            \n",
    "            result = response.json()\n",
    "            \n",
    "            # Cache the result\n",
    "            self.cache[cache_key] = result\n",
    "            \n",
    "            return result\n",
    "        \n",
    "        except requests.exceptions.RequestException as e:\n",
    "            logger.error(f\"Error querying Google Fact Check API: {str(e)}\")\n",
    "            return {\"error\": str(e), \"claims\": []}\n",
    "    \n",
    "    def process_fact_check_results(self, results: Dict[str, Any]) -> Tuple[float, List[Dict[str, Any]]]:\n",
    "        \"\"\"\n",
    "        Process fact-check results to determine credibility score.\n",
    "        \n",
    "        Args:\n",
    "            results: The raw results from the fact_check_claim method\n",
    "            \n",
    "        Returns:\n",
    "            Tuple containing:\n",
    "            - credibility_score: Float between 0.0 (likely fake) and 1.0 (likely true)\n",
    "            - evidence: List of dictionaries containing supporting evidence\n",
    "        \"\"\"\n",
    "        if \"error\" in results:\n",
    "            logger.warning(f\"Cannot process results due to error: {results['error']}\")\n",
    "            return 0.5, []  # Neutral score when API fails\n",
    "        \n",
    "        claims = results.get(\"claims\", [])\n",
    "        if not claims:\n",
    "            logger.info(\"No fact-check results found for the claim\")\n",
    "            return 0.5, []  # Neutral score when no results\n",
    "        \n",
    "        evidence = []\n",
    "        rating_sum = 0.0\n",
    "        rating_count = 0\n",
    "        \n",
    "        for claim in claims:\n",
    "            claim_reviews = claim.get(\"claimReview\", [])\n",
    "            \n",
    "            for review in claim_reviews:\n",
    "                # Extract publisher info\n",
    "                publisher = review.get(\"publisher\", {}).get(\"name\", \"Unknown Source\")\n",
    "                \n",
    "                # Extract rating\n",
    "                rating_value = self._extract_rating_value(review)\n",
    "                if rating_value is not None:\n",
    "                    rating_sum += rating_value\n",
    "                    rating_count += 1\n",
    "                \n",
    "                # Collect evidence\n",
    "                evidence.append({\n",
    "                    \"publisher\": publisher,\n",
    "                    \"title\": review.get(\"title\", \"\"),\n",
    "                    \"url\": review.get(\"url\", \"\"),\n",
    "                    \"rating\": review.get(\"textualRating\", \"\"),\n",
    "                    \"rating_value\": rating_value\n",
    "                })\n",
    "        \n",
    "        # Calculate average credibility score\n",
    "        credibility_score = rating_sum / rating_count if rating_count > 0 else 0.5\n",
    "        \n",
    "        return credibility_score, evidence\n",
    "    \n",
    "    def _extract_rating_value(self, review: Dict[str, Any]) -> Optional[float]:\n",
    "        \"\"\"\n",
    "        Extract a normalized rating value from a review.\n",
    "        \n",
    "        Args:\n",
    "            review: A single review from the fact-check results\n",
    "            \n",
    "        Returns:\n",
    "            Float between 0.0 (false) and 1.0 (true), or None if not available\n",
    "        \"\"\"\n",
    "        # Try to get the rating value\n",
    "        rating = review.get(\"textualRating\", \"\").lower()\n",
    "        \n",
    "        # Map common rating terms to numerical values\n",
    "        if any(term in rating for term in [\"false\", \"pants on fire\", \"fake\"]):\n",
    "            return 0.0\n",
    "        elif any(term in rating for term in [\"mostly false\", \"misleading\"]):\n",
    "            return 0.25\n",
    "        elif any(term in rating for term in [\"mixture\", \"half true\", \"partly\"]):\n",
    "            return 0.5\n",
    "        elif any(term in rating for term in [\"mostly true\"]):\n",
    "            return 0.75\n",
    "        elif any(term in rating for term in [\"true\", \"correct\", \"accurate\"]):\n",
    "            return 1.0\n",
    "        \n",
    "        # If no match, try to extract numerical rating\n",
    "        try:\n",
    "            rating_value = float(review.get(\"ratingValue\", 0))\n",
    "            max_rating = float(review.get(\"maxRating\", 1))\n",
    "            return rating_value / max_rating\n",
    "        except (ValueError, TypeError, ZeroDivisionError):\n",
    "            return None\n",
    "    \n",
    "    def check_claim_credibility(self, claim: str) -> Dict[str, Any]:\n",
    "        \"\"\"\n",
    "        High-level method to check the credibility of a claim.\n",
    "        \n",
    "        Args:\n",
    "            claim: The claim to check\n",
    "            \n",
    "        Returns:\n",
    "            Dictionary with credibility assessment and evidence\n",
    "        \"\"\"\n",
    "        # Query the fact-check API\n",
    "        fact_check_results = self.fact_check_claim(claim)\n",
    "        \n",
    "        # Process the results\n",
    "        credibility_score, evidence = self.process_fact_check_results(fact_check_results)\n",
    "        \n",
    "        return {\n",
    "            \"claim\": claim,\n",
    "            \"credibility_score\": credibility_score,\n",
    "            \"evidence\": evidence,\n",
    "            \"has_fact_checks\": len(evidence) > 0\n",
    "        }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Result Integrator Implementation\n",
    "\n",
    "This component integrates results from different sources (e.g., CLIP model and fact-checking)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "class ResultIntegrator:\n",
    "    \"\"\"\n",
    "    Module for integrating CLIP model predictions with fact-check results.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, clip_weight: float = 0.6, fact_check_weight: float = 0.4):\n",
    "        \"\"\"\n",
    "        Initialize the ResultIntegrator.\n",
    "        \n",
    "        Args:\n",
    "            clip_weight: Weight given to CLIP model prediction (default: 0.6)\n",
    "            fact_check_weight: Weight given to fact-check results (default: 0.4)\n",
    "        \"\"\"\n",
    "        self.clip_weight = clip_weight\n",
    "        self.fact_check_weight = fact_check_weight\n",
    "        \n",
    "        # Ensure weights sum to 1.0\n",
    "        total_weight = self.clip_weight + self.fact_check_weight\n",
    "        if total_weight != 1.0:\n",
    "            self.clip_weight /= total_weight\n",
    "            self.fact_check_weight /= total_weight\n",
    "            \n",
    "        logger.info(f\"Initialized ResultIntegrator with weights: CLIP={self.clip_weight:.2f}, Fact-check={self.fact_check_weight:.2f}\")\n",
    "    \n",
    "    def integrate_results(self, \n",
    "                         clip_result: Dict[str, Any], \n",
    "                         fact_check_results: List[Dict[str, Any]]) -> Dict[str, Any]:\n",
    "        \"\"\"\n",
    "        Integrate CLIP model prediction with fact-check results.\n",
    "        \n",
    "        Args:\n",
    "            clip_result: Dictionary containing CLIP model prediction\n",
    "                Expected format: {\"label\": 0 or 1, \"confidence\": float}\n",
    "                where 0 = fake, 1 = real\n",
    "            fact_check_results: List of dictionaries containing fact-check results\n",
    "                Expected format: [{\"claim\": str, \"credibility_score\": float, \"evidence\": list}]\n",
    "        \n",
    "        Returns:\n",
    "            Dictionary containing integrated results\n",
    "        \"\"\"\n",
    "        # Extract CLIP prediction\n",
    "        clip_label = clip_result.get(\"label\", 0)\n",
    "        clip_confidence = clip_result.get(\"confidence\", 0.5)\n",
    "        \n",
    "        # Convert CLIP binary label to score (0 = fake = 0.0, 1 = real = 1.0)\n",
    "        clip_score = float(clip_label)\n",
    "        \n",
    "        # Apply confidence to make the score more nuanced\n",
    "        # If label is 0 (fake), confidence of 0.8 means score of 0.2\n",
    "        # If label is 1 (real), confidence of 0.8 means score of 0.8\n",
    "        if clip_label == 0:\n",
    "            clip_score = 1.0 - clip_confidence\n",
    "        else:\n",
    "            clip_score = clip_confidence\n",
    "            \n",
    "        logger.info(f\"CLIP score: {clip_score:.4f} (label={clip_label}, confidence={clip_confidence:.4f})\")\n",
    "        \n",
    "        # Process fact-check results\n",
    "        if not fact_check_results:\n",
    "            logger.warning(\"No fact-check results provided, using CLIP prediction only\")\n",
    "            return self._prepare_final_result(clip_score, None, clip_result, [])\n",
    "        \n",
    "        # Calculate average credibility score from fact-check results\n",
    "        total_score = 0.0\n",
    "        total_weight = 0.0\n",
    "        all_evidence = []\n",
    "        \n",
    "        for result in fact_check_results:\n",
    "            credibility_score = result.get(\"credibility_score\", 0.5)\n",
    "            evidence = result.get(\"evidence\", [])\n",
    "            claim = result.get(\"claim\", \"\")\n",
    "            \n",
    "            # Weight by evidence count (more evidence = more reliable)\n",
    "            weight = min(len(evidence), 5) / 5.0 if evidence else 0.5\n",
    "            total_score += credibility_score * weight\n",
    "            total_weight += weight\n",
    "            \n",
    "            # Collect all evidence\n",
    "            all_evidence.extend(evidence)\n",
    "            \n",
    "            logger.info(f\"Fact-check for claim '{claim[:30]}...': score={credibility_score:.4f}, weight={weight:.2f}\")\n",
    "        \n",
    "        # Calculate weighted average of fact-check scores\n",
    "        fact_check_score = total_score / total_weight if total_weight > 0 else 0.5\n",
    "        logger.info(f\"Overall fact-check score: {fact_check_score:.4f}\")\n",
    "        \n",
    "        # Integrate CLIP and fact-check scores\n",
    "        return self._prepare_final_result(clip_score, fact_check_score, clip_result, fact_check_results)\n",
    "    \n",
    "    def _prepare_final_result(self, \n",
    "                             clip_score: float, \n",
    "                             fact_check_score: Optional[float], \n",
    "                             clip_result: Dict[str, Any],\n",
    "                             fact_check_results: List[Dict[str, Any]]) -> Dict[str, Any]:\n",
    "        \"\"\"\n",
    "        Prepare the final integrated result.\n",
    "        \n",
    "        Args:\n",
    "            clip_score: Score from CLIP model (0.0 to 1.0)\n",
    "            fact_check_score: Score from fact-check results (0.0 to 1.0) or None\n",
    "            clip_result: Original CLIP result dictionary\n",
    "            fact_check_results: List of fact-check result dictionaries\n",
    "            \n",
    "        Returns:\n",
    "            Dictionary containing final integrated results\n",
    "        \"\"\"\n",
    "        # If no fact-check score, use only CLIP score\n",
    "        if fact_check_score is None:\n",
    "            integrated_score = clip_score\n",
    "            weights_used = {\"clip\": 1.0, \"fact_check\": 0.0}\n",
    "        else:\n",
    "            # Weighted average of CLIP and fact-check scores\n",
    "            integrated_score = (clip_score * self.clip_weight) + (fact_check_score * self.fact_check_weight)\n",
    "            weights_used = {\"clip\": self.clip_weight, \"fact_check\": self.fact_check_weight}\n",
    "        \n",
    "        logger.info(f\"Integrated score: {integrated_score:.4f}\")\n",
    "        \n",
    "        # Determine final label and confidence\n",
    "        final_label = 1 if integrated_score >= 0.5 else 0\n",
    "        final_confidence = abs(integrated_score - 0.5) * 2  # Scale to 0-1\n",
    "        \n",
    "        # Collect evidence from fact-check results\n",
    "        all_evidence = []\n",
    "        for result in fact_check_results:\n",
    "            evidence = result.get(\"evidence\", [])\n",
    "            claim = result.get(\"claim\", \"\")\n",
    "            all_evidence.extend([{**item, \"claim\": claim} for item in evidence])\n",
    "        \n",
    "        # Prepare final result\n",
    "        final_result = {\n",
    "            \"label\": final_label,  # 0 = fake, 1 = real\n",
    "            \"label_text\": \"real\" if final_label == 1 else \"fake\",\n",
    "            \"confidence\": final_confidence,\n",
    "            \"integrated_score\": integrated_score,\n",
    "            \"component_scores\": {\n",
    "                \"clip\": clip_score,\n",
    "                \"fact_check\": fact_check_score\n",
    "            },\n",
    "            \"weights_used\": weights_used,\n",
    "            \"evidence\": all_evidence,\n",
    "            \"clip_details\": clip_result,\n",
    "            \"fact_check_details\": fact_check_results\n",
    "        }\n",
    "        \n",
    "        return final_result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Fake News Detector Implementation\n",
    "\n",
    "This is the main component that orchestrates the entire process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "class FakeNewsDetector:\n",
    "    \"\"\"\n",
    "    Main controller for fake news detection with web search integration.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, \n",
    "                api_key: Optional[str] = None,\n",
    "                clip_weight: float = 0.6,\n",
    "                fact_check_weight: float = 0.4,\n",
    "                max_claims: int = 3):\n",
    "        \"\"\"\n",
    "        Initialize the FakeNewsDetector.\n",
    "        \n",
    "        Args:\n",
    "            api_key: API key for Google Fact Check API\n",
    "            clip_weight: Weight given to CLIP model prediction\n",
    "            fact_check_weight: Weight given to fact-check results\n",
    "            max_claims: Maximum number of claims to extract and check\n",
    "        \"\"\"\n",
    "        self.api_key = api_key or API_KEY\n",
    "        self.max_claims = max_claims\n",
    "        \n",
    "        # Initialize components\n",
    "        logger.info(\"Initializing FakeNewsDetector components\")\n",
    "        self.claim_extractor = ClaimExtractor()\n",
    "        self.web_search = WebSearchModule(api_key=self.api_key)\n",
    "        self.result_integrator = ResultIntegrator(clip_weight, fact_check_weight)\n",
    "        \n",
    "        # CLIP model is not included in this notebook\n",
    "        # In a real implementation, you would load it here\n",
    "        self.clip_model = None\n",
    "    \n",
    "    def detect_web_search_only(self, text: str) -> Dict[str, Any]:\n",
    "        \"\"\"\n",
    "        Detect fake news using only web search (without CLIP model).\n",
    "        \n",
    "        Args:\n",
    "            text: The news text to classify\n",
    "            \n",
    "        Returns:\n",
    "            Dictionary containing the detection result\n",
    "        \"\"\"\n",
    "        logger.info(f\"Processing text with web search only (length {len(text)} characters)\")\n",
    "        \n",
    "        # Extract claims from text\n",
    "        claims = self.claim_extractor.extract_claims(text)\n",
    "        logger.info(f\"Extracted {len(claims)} claims from text\")\n",
    "        \n",
    "        # Rank and select top claims\n",
    "        top_claims = self.claim_extractor.rank_claims(claims, top_n=self.max_claims)\n",
    "        logger.info(f\"Selected top {len(top_claims)} claims for fact-checking\")\n",
    "        \n",
    "        # Check claims with web search\n",
    "        fact_check_results = []\n",
    "        for claim in top_claims:\n",
    "            result = self.web_search.check_claim_credibility(claim)\n",
    "            fact_check_results.append(result)\n",
    "            logger.info(f\"Fact-check for claim '{claim[:30]}...': score={result['credibility_score']:.4f}\")\n",
    "        \n",
    "        # Calculate average credibility score\n",
    "        if fact_check_results:\n",
    "            total_score = sum(r['credibility_score'] for r in fact_check_results)\n",
    "            avg_score = total_score / len(fact_check_results)\n",
    "        else:\n",
    "            avg_score = 0.5  # Neutral score if no results\n",
    "        \n",
    "        # Determine final label and confidence\n",
    "        final_label = 1 if avg_score >= 0.5 else 0\n",
    "        final_confidence = abs(avg_score - 0.5) * 2  # Scale to 0-1\n",
    "        \n",
    "        # Collect all evidence\n",
    "        all_evidence = []\n",
    "        for result in fact_check_results:\n",
    "            evidence = result.get(\"evidence\", [])\n",
    "            claim = result.get(\"claim\", \"\")\n",
    "            all_evidence.extend([{**item, \"claim\": claim} for item in evidence])\n",
    "        \n",
    "        return {\n",
    "            \"label\": final_label,  # 0 = fake, 1 = real\n",
    "            \"label_text\": \"real\" if final_label == 1 else \"fake\",\n",
    "            \"confidence\": final_confidence,\n",
    "            \"credibility_score\": avg_score,\n",
    "            \"claims_checked\": top_claims,\n",
    "            \"fact_check_results\": fact_check_results,\n",
    "            \"evidence\": all_evidence\n",
    "        }\n",
    "    \n",
    "    def detect(self, text: str, image_path: Optional[str] = None) -> Dict[str, Any]:\n",
    "        \"\"\"\n",
    "        Detect fake news using both CLIP model and web search.\n",
    "        Note: This method is a placeholder since we don't have the CLIP model in this notebook.\n",
    "        \n",
    "        Args:\n",
    "            text: The news text to classify\n",
    "            image_path: Path to the associated image (optional)\n",
    "            \n",
    "        Returns:\n",
    "            Dictionary containing the detection result\n",
    "        \"\"\"\n",
    "        logger.warning(\"CLIP model is not available in this notebook. Using web search only.\")\n",
    "        \n",
    "        # In a real implementation, you would:\n",
    "        # 1. Make prediction with CLIP model\n",
    "        # 2. Extract and check claims with web search\n",
    "        # 3. Integrate results\n",
    "        \n",
    "        # For now, just use web search\n",
    "        web_search_result = self.detect_web_search_only(text)\n",
    "        \n",
    "        # Create a mock CLIP result\n",
    "        mock_clip_result = {\n",
    "            \"label\": web_search_result[\"label\"],  # Use the same label for demonstration\n",
    "            \"confidence\": 0.7  # Arbitrary confidence value\n",
    "        }\n",
    "        \n",
    "        # Integrate the results (this will be weighted heavily toward the web search result)\n",
    "        return self.result_integrator.integrate_results(\n",
    "            mock_clip_result, \n",
    "            web_search_result[\"fact_check_results\"]\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Testing the Implementation\n",
    "\n",
    "Let's test the fake news detection system with some example news texts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Initialize the detector with your API key\n",
    "detector = FakeNewsDetector(api_key=API_KEY)\n",
    "\n",
    "# Test cases\n",
    "test_cases = [\n",
    "    {\n",
    "        \"title\": \"Likely Fake News (COVID-19 microchips)\",\n",
    "        \"text\": \"\"\"\n",
    "        Breaking News: Scientists have discovered that COVID-19 vaccines contain microchips \n",
    "        that allow governments to track individuals. According to Dr. John Smith, these \n",
    "        microchips are activated by 5G networks and can control people's thoughts. \n",
    "        The World Health Organization has been hiding this information from the public.\n",
    "        \"\"\"\n",
    "    },\n",
    "    {\n",
    "        \"title\": \"Likely Real News (Health benefits)\",\n",
    "        \"text\": \"\"\"\n",
    "        A new study published in the Journal of Medicine found that regular exercise \n",
    "        can reduce the risk of heart disease by up to 30%. The research, conducted over \n",
    "        a 10-year period with 5,000 participants, shows a clear correlation between \n",
    "        physical activity and cardiovascular health. Health experts recommend at least \n",
    "        150 minutes of moderate exercise per week.\n",
    "        \"\"\"\n",
    "    },\n",
    "    {\n",
    "        \"title\": \"Conspiracy Theory (Flat Earth)\",\n",
    "        \"text\": \"\"\"\n",
    "        New evidence suggests that the Earth is actually flat, contrary to what scientists \n",
    "        have been telling us for centuries. Photos from space are manipulated by NASA to \n",
    "        maintain the illusion of a spherical Earth. The truth is being hidden from the public \n",
    "        to maintain control over the population.\n",
    "        \"\"\"\n",
    "    }\n",
    "]\n",
    "\n",
    "# Process each test case\n",
    "for i, test_case in enumerate(test_cases, 1):\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(f\"Test Case {i}: {test_case['title']}\")\n",
    "    print(\"-\"*80)\n",
    "    print(f\"Text: {test_case['text'].strip()}\")\n",
    "    print(\"-\"*80)\n",
    "    \n",
    "    # Detect fake news using web search only\n",
    "    result = detector.detect_web_search_only(test_case[\"text\"])\n",
    "    \n",
    "    # Print the result\n",
    "    print(f\"Verdict: {result['label_text'].upper()}\")\n",
    "    print(f\"Confidence: {result['confidence']:.2f}\")\n",
    "    \n",
    "    # Print claims checked\n",
    "    if result['claims_checked']:\n",
    "        print(\"\\nClaims checked:\")\n",
    "        for j, claim in enumerate(result['claims_checked'], 1):\n",
    "            print(f\"{j}. {claim}\")\n",
    "    \n",
    "    # Print evidence\n",
    "    if result['evidence']:\n",
    "        print(\"\\nEvidence:\")\n",
    "        for j, item in enumerate(result['evidence'], 1):\n",
    "            print(f\"{j}. {item['publisher']}: {item['rating']}\")\n",
    "            print(f\"   URL: {item['url']}\")\n",
    "    else:\n",
    "        print(\"\\nNo fact-check evidence found.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Try Your Own Text\n",
    "\n",
    "Now you can try the system with your own text:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Get text from user\n",
    "user_text = input(\"Enter your text to check for fake news: \")\n",
    "\n",
    "if user_text:\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"Processing your text...\")\n",
    "    print(\"-\"*80)\n",
    "    \n",
    "    # Detect fake news using web search only\n",
    "    result = detector.detect_web_search_only(user_text)\n",
    "    \n",
    "    # Print the result\n",
    "    print(f\"Verdict: {result['label_text'].upper()}\")\n",
    "    print(f\"Confidence: {result['confidence']:.2f}\")\n",
    "    \n",
    "    # Print claims checked\n",
    "    if result['claims_checked']:\n",
    "        print(\"\\nClaims checked:\")\n",
    "        for j, claim in enumerate(result['claims_checked'], 1):\n",
    "            print(f\"{j}. {claim}\")\n",
    "    \n",
    "    # Print evidence\n",
    "    if result['evidence']:\n",
    "        print(\"\\nEvidence:\")\n",
    "        for j, item in enumerate(result['evidence'], 1):\n",
    "            print(f\"{j}. {item['publisher']}: {item['rating']}\")\n",
    "            print(f\"   URL: {item['url']}\")\n",
    "    else:\n",
    "        print(\"\\nNo fact-check evidence found.\")\n",
    "else:\n",
    "    print(\"No text entered.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Conclusion\n",
    "\n",
    "This notebook has demonstrated a complete implementation of a fake news detection system with web search integration using the Google Fact Check API. The system:\n",
    "\n",
    "1. Extracts claims from news text using NLP techniques\n",
    "2. Checks these claims against the Google Fact Check API\n",
    "3. Determines the credibility of the news based on fact-check results\n",
    "\n",
    "For a full implementation, you would integrate this with a CLIP-based model for multimodal analysis, which would improve the accuracy of the system by considering both textual and visual content.\n",
    "\n",
    "### Next Steps\n",
    "\n",
    "1. Integrate with a real CLIP model for multimodal analysis\n",
    "2. Improve the claim extraction with more sophisticated NLP techniques\n",
    "3. Add support for multiple languages\n",
    "4. Implement a caching system for faster processing\n",
    "5. Add support for other fact-checking APIs"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
